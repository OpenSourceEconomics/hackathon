{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Webscraping in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an introduction into webscraping with the Python library `BeautifulSoup`. A full documentation on the package can be found [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#modifying-the-tree\"). To initially install the package, type \n",
    "`pip install beautifulsoup4` in the Anaconda command line. In addition install a parser by typing `pip install lxml` or `pip install html5lib`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a start we need one package that allows us to download the html-file (`requests`), one parser (`html5lib`or `lxml`), `BeautifulSoup` itself, which enables us to make use of the structure of the file to search and navigate through it more easly, and `re` to search using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import html5lib\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "The examples in this notebook are based on a research project of Matt Lowe. Final results of the scrape can be found in his paper [Now You See Me: The Returns to Visibility for Politicians, Lowe 2019 WP](https://mfr.osf.io/render?url=https://osf.io/c23tg/?action=download%26mode=render). We investigate a natural experiment that occurs in the British Parliament every week. MP's can enter the name to ask the Prime Minister a question. 10-15 of those who put their name down are randomly selected and get to ask a question in a (commonly) well attended parliamentary hall and benefit as well from the popularity of this format in the media. Lowe uses the treatment of getting to ask a question as an exogenous shock to the politicians visibility to his or her respective party leaders and studies the effects of this visibility shock on future career performance. Therefore we want to extract for every *date* this Prime Minister Questions (PMQ) format took place information at the *speech-level* regarding *speaker* and whether or not the speech was a *question*. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Fetch the HTML-page of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://hansard.parliament.uk/Commons/1982-07-27/debates/7a87ccce-4da2-42b2-96b8-718f36f651b0/Engagements\"\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Brew the soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brew_the_soup(content_page,parser_str):\n",
    "    soup = BeautifulSoup(content_page,parser_str)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 ms ± 12.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit brew_the_soup(page.content,'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.4 ms ± 6.28 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit brew_the_soup(page.content,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lxml` performs way fast than `html5lib` and should usually be considered the option of choice. Very rarely HTML-files are formatted weirdly and `lxml` does not capture all of the source code (happened to me once so far). Then `html5lib` can make sure, that no content is lost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Search & Navigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the core of our scraping routine. Now we use (i) the structural commands of `BeautifulSoup`and (ii) customized regular expressions with `re` to extract the bits of information from the html-file that we are after. \n",
    "In this case we want the links of the two PMQ sessions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I) Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two fundamental ways to search for elements of the html file:\n",
    "`soup.find(tagname, attrs)` and `soup.findAll(tagname,attrs)`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"memberLink col-md-9\" id=\"member-link-db588e6f-becc-46ef-9105-744edd82b68d\">\n",
       "                The Prime Minister\n",
       "            </h2>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2',text=re.compile(r'The Prime Minister'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2 class=\"memberLink col-md-9\" id=\"member-link-db588e6f-becc-46ef-9105-744edd82b68d\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-2c72979e-590e-4734-b131-cff782d12521\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-84e51054-cf58-4b84-a1dc-1ee2aba2108a\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-d4ca3754-2040-4520-a829-aa6725123cd6\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-b8ab825a-7513-43be-af16-c08271324f83\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-397a793b-6328-4133-b145-03fbc00f0d74\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-d536887a-fba8-4272-bc5d-ca6f20a498f9\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-a009c4c4-1c0b-4fc2-ab3a-9435618f5e58\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-76ec73c3-338f-4ce9-a8b9-43c3612989b6\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-c8698829-98a8-4527-a405-c7a72c8404ba\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-7e896a30-8598-4622-9552-cc8a03a3a3ca\">\n",
       "                 The Prime Minister\n",
       "             </h2>,\n",
       " <h2 class=\"memberLink col-md-9\" id=\"member-link-72d60072-775f-44d4-9e95-6a72ba9d2279\">\n",
       "                 The Prime Minister\n",
       "             </h2>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('h2',text=re.compile(r'The Prime Minister'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II) Navigating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot only search for tags *absolutely* using the two commands from above, but also move *relative* to a designated tag in all directions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going Upwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q2.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text='Q2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "div\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "for parent in soup.find(text='Q2.').parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also combine navigation and searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content-item other-content\">\n",
       "<!-- START statement -->\n",
       "<div class=\"statement col-md-9 content-container\" id=\"contribution-7439638f-cfb2-4f61-8334-d9b09743eaf0\">\n",
       "<p class=\"\">Q2.</p>\n",
       "</div>\n",
       "<div class=\"col-md-3 hidden-sm hidden-xs right-column\">\n",
       "</div>\n",
       "<div class=\"clearfix\"></div>\n",
       "<!-- END statement -->\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text='Q2.').find_parent('div',class_=\"content-item other-content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_container = soup.find(class_=\"content-container\")\n",
    "#content_container"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get tags that are *direct* children of the initial tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content-item', 'other-content']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item', 'other-content']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item', 'other-content']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n"
     ]
    }
   ],
   "source": [
    "for item in content_container.children:\n",
    "    if not isinstance(item,str):\n",
    "        print(item['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even *recursively iterate* through all tags that are nested within the inital tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-16-319163f6f053>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-319163f6f053>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    #print(item.attrs)\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for item in content_container.descendants:\n",
    "    if not isinstance(item,str):\n",
    "        #print(item.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going Sideways \n",
    "And lastly you can also go sideways, however a bit more restricted. To get all *siblings* of a tag, you need to use to commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content-item\" id=\"contribution-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\">\n",
       "<div class=\"col-md-9 edit-fail-error\">\n",
       "<div class=\"alert alert-danger\" id=\"alert-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\">\n",
       "<span class=\"glyphicon glyphicon-info-sign\"></span>The edit just sent has not been saved.  The following error was returned:\n",
       "        </div>\n",
       "</div>\n",
       "<div class=\"col-md-9 multiple-edit-warning\">\n",
       "<div class=\"alert alert-warning\" id=\"warning-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\">\n",
       "<span class=\"glyphicon glyphicon-info-sign\"></span>This content has already been edited and is awaiting review.\n",
       "        </div>\n",
       "</div>\n",
       "<div class=\"col-md-9 nohighlight member-container\">\n",
       "<h2 class=\"memberLink col-md-9\" id=\"member-link-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\">\n",
       "                Mr. Delwyn Williams\n",
       "            </h2>\n",
       "</div>\n",
       "<div class=\"col-md-3 hidden-sm hidden-xs right-column\">\n",
       "<a class=\"link-to-contribution link-text\" data-hop-popover=\"http://hansard.parliament.uk/Commons/1982-07-27/debates/7a87ccce-4da2-42b2-96b8-718f36f651b0/Engagements#contribution-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\" data-hop-url-shorten-url=\"/UrlShortener/ShorternUrl\" data-placement=\"top\" href=\"#contribution-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\" rel=\"popover\" title=\"Share this contribution\">\n",
       "<div class=\"share-icon\"> </div><span class=\"share-text\">Share</span>\n",
       "</a>\n",
       "</div>\n",
       "<div class=\"inner\">\n",
       "<div class=\"col-md-9 contribution content-container\">\n",
       "<p class=\"\">asked the Prime Minister if she will list her official engagements for Tuesday 27 July.</p> <div class=\"hidden-md hidden-lg\" style=\"padding-left: 0px;\">\n",
       "<a class=\"link-to-contribution link-to-contribution-mobile link-text\" data-hop-popover=\"http://hansard.parliament.uk/Commons/1982-07-27/debates/7a87ccce-4da2-42b2-96b8-718f36f651b0/Engagements#contribution-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\" data-hop-url-shorten-url=\"/UrlShortener/ShorternUrl\" data-placement=\"top\" href=\"#contribution-d284e83d-8a4d-4b5d-bd45-d7ad24e78bca\" rel=\"popover\" title=\"Share this contribution\">\n",
       "<div class=\"share-icon\"> </div> Share\n",
       "                        </a>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"clearfix\"></div>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_item = content_container.find('div',class_=\"content-item\",id=True)\n",
    "content_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_item = content_item.next_sibling.next_sibling\n",
    "#previous_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n",
      "['content-item']\n"
     ]
    }
   ],
   "source": [
    "for item in content_item.find_next_siblings(id=True):\n",
    "    print(item['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to extract the relevant information into a structured data object. In most cases we need the actual content, i.e. the string or bits of a string of a HTML-tag, bit in principle we can also extract, all other attributes such as `class`, `id`, `href`, etc.\n",
    "We will now construct a dataframe at the speech-level with 4 variables on question number, question dummy, speaker name and speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_number = list()\n",
    "speaker = list()\n",
    "speech = list()\n",
    "question_indicator = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ptrn = r'Q(\\d)+\\.?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a state variable that indicates whether the last item was of class \"content-item\" (0) or \"content-item other-content\" (1)\n",
    "previous_item = 0\n",
    "for item in content_container.children:\n",
    "    if not isinstance(item,str):\n",
    "        if len(item['class']) > 1:\n",
    "            q_match = re.search(q_ptrn,item.text)\n",
    "            if bool(q_match):\n",
    "                question_number.append(int(q_match.group(1)))\n",
    "            else:\n",
    "                question_number.append(pd.NaT)\n",
    "            previous_item = 1\n",
    "\n",
    "        else:\n",
    "            if previous_item == 1:\n",
    "                previous_item = 0\n",
    "                question_indicator.append(1)\n",
    "            else:\n",
    "                question_number.append(pd.NaT)\n",
    "                question_indicator.append(0)\n",
    "\n",
    "\n",
    "            speaker_container = item.find('div',class_=\"col-md-9 nohighlight member-container\")\n",
    "            speech_container = item.find('div', class_=\"col-md-9 contribution content-container\")\n",
    "\n",
    "            speaker.append(str.strip(speaker_container.text))\n",
    "            speech.append(str.strip(speech_container.text))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['question'] = question_indicator\n",
    "df['question_number'] = question_number\n",
    "df['speaker'] = speaker\n",
    "df['speech'] = speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_number</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr. Delwyn Williams</td>\n",
       "      <td>asked the Prime Minister if she will list her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>This morning I had meetings with ministerial c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Williams</td>\n",
       "      <td>Is my right hon. Friend not dismayed by the de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>I understand that the suggestion of lowering e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mrs. Shirley Williams</td>\n",
       "      <td>Has the Prime Minister seen the report of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>The report is not mine in any way. I have seen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Allen McKay</td>\n",
       "      <td>Is the right hon. Lady aware of the agricultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>The hon. Gentleman knows that the agricultural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Beaumont-Dark</td>\n",
       "      <td>Will my right hon. Friend express regret that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>I agree with my hon. Friend. If allegations, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Greville Janner</td>\n",
       "      <td>asked the Prime Minister if she will list her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>I refer the hon. and learned Gentleman to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Janner</td>\n",
       "      <td>Is the Prime Minister aware that today 25,407 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>First, we shall keep inflation coming down. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Thornton</td>\n",
       "      <td>Has my right hon. Friend had an opportunity to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>I agree that it is a wonderful boost for Merse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Barry Jones</td>\n",
       "      <td>Has the Prime Minister noted the intense disap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>The hon. Gentleman will have seen the announce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Tapsell</td>\n",
       "      <td>Has my right hon. Friend noted the growing anx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>I am very much aware of that and of the danger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Mr. Dormand</td>\n",
       "      <td>asked the Prime Minister if she will list her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>I refer the hon. Gentleman to the reply that I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Mr. Dormand</td>\n",
       "      <td>I support my right hon. Friend the Leader of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>The Prime Minister</td>\n",
       "      <td>The Government have already offered a subsidy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question question_number                speaker  \\\n",
       "0          1               2    Mr. Delwyn Williams   \n",
       "1          0             NaT     The Prime Minister   \n",
       "2          0             NaT           Mr. Williams   \n",
       "3          0             NaT     The Prime Minister   \n",
       "4          0             NaT  Mrs. Shirley Williams   \n",
       "5          0             NaT     The Prime Minister   \n",
       "6          0             NaT        Mr. Allen McKay   \n",
       "7          0             NaT     The Prime Minister   \n",
       "8          0             NaT      Mr. Beaumont-Dark   \n",
       "9          0             NaT     The Prime Minister   \n",
       "10         1               3    Mr. Greville Janner   \n",
       "11         0             NaT     The Prime Minister   \n",
       "12         0             NaT             Mr. Janner   \n",
       "13         0             NaT     The Prime Minister   \n",
       "14         0             NaT           Mr. Thornton   \n",
       "15         0             NaT     The Prime Minister   \n",
       "16         0             NaT        Mr. Barry Jones   \n",
       "17         0             NaT     The Prime Minister   \n",
       "18         0             NaT            Mr. Tapsell   \n",
       "19         0             NaT     The Prime Minister   \n",
       "20         1               4            Mr. Dormand   \n",
       "21         0             NaT     The Prime Minister   \n",
       "22         0             NaT            Mr. Dormand   \n",
       "23         0             NaT     The Prime Minister   \n",
       "\n",
       "                                               speech  \n",
       "0   asked the Prime Minister if she will list her ...  \n",
       "1   This morning I had meetings with ministerial c...  \n",
       "2   Is my right hon. Friend not dismayed by the de...  \n",
       "3   I understand that the suggestion of lowering e...  \n",
       "4   Has the Prime Minister seen the report of the ...  \n",
       "5   The report is not mine in any way. I have seen...  \n",
       "6   Is the right hon. Lady aware of the agricultur...  \n",
       "7   The hon. Gentleman knows that the agricultural...  \n",
       "8   Will my right hon. Friend express regret that ...  \n",
       "9   I agree with my hon. Friend. If allegations, s...  \n",
       "10  asked the Prime Minister if she will list her ...  \n",
       "11  I refer the hon. and learned Gentleman to the ...  \n",
       "12  Is the Prime Minister aware that today 25,407 ...  \n",
       "13  First, we shall keep inflation coming down. Th...  \n",
       "14  Has my right hon. Friend had an opportunity to...  \n",
       "15  I agree that it is a wonderful boost for Merse...  \n",
       "16  Has the Prime Minister noted the intense disap...  \n",
       "17  The hon. Gentleman will have seen the announce...  \n",
       "18  Has my right hon. Friend noted the growing anx...  \n",
       "19  I am very much aware of that and of the danger...  \n",
       "20  asked the Prime Minister if she will list her ...  \n",
       "21  I refer the hon. Gentleman to the reply that I...  \n",
       "22  I support my right hon. Friend the Leader of t...  \n",
       "23  The Government have already offered a subsidy ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Strategy for larger projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make things robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were lucky so far that we always found what we were looking for where we were looking for it. In practice, you will need try and except a lot. In my experience it makes sense to incorporate these into robust versions of the basic search-commands from `BeautifulSoup`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_tag_finder(start_soup, tagname, attribute=\"parent\", **kwargs):\n",
    "    \"\"\"\n",
    "    Try to find the next tag that satisfies the specified criteria and return a \n",
    "    None object if the search does not succeed.\n",
    "    Args:\n",
    "        start_soup(soup): The soup object from which the find algorithm starts.\n",
    "        tagname(str): Specifies that name of the tags that should be searched for.\n",
    "        attribute(str)(optional): Specifies the attribute of the found tag that is returned. \n",
    "        By default the parent of the tag is returned. \n",
    "    Output:\n",
    "        found_soup(soup): The soup object that satisfies the stated criteria.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        found_soup = getattr(start_soup.find(tagname, **kwargs), attribute)\n",
    "    except:\n",
    "        found_soup = None\n",
    "\n",
    "    return found_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAll_surrounding_tags(start_tag, tag_name, previous_steps=None, next_steps=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Find all previous and next steps that satisfy certain criteria starting from\n",
    "    a start_tag and store them in a list.\n",
    "    Args:\n",
    "        start_tag(soup): A soup object from which surrounding tags are searched.\n",
    "        previous_steps(int): Specifies the number of previous tags that are searched for.\n",
    "        next_steps(int): Specifies the number of next tags that are searched for.\n",
    "        tag_name(str): Specifies name of the tags that are searched for.\n",
    "        **kwargs(optional): Further searching criteria can be passed.\n",
    "    Output:\n",
    "        tag_list(list): A list of all found previous and next tags that satisfy \n",
    "        the stated criteria.\n",
    "    \"\"\"\n",
    "    tag_list = []\n",
    "\n",
    "    # Previous steps\n",
    "    if previous_steps is not None:\n",
    "        following_tag = start_tag\n",
    "        for n in range(1, previous_steps):\n",
    "            if following_tag is not None:\n",
    "                previous_tag = following_tag.find_previous_sibling(tag_name, **kwargs)\n",
    "                following_tag = previous_tag\n",
    "                if previous_tag is not None:\n",
    "                    tag_list.append(previous_tag)\n",
    "            else:\n",
    "                break\n",
    "        # The tags need to be in chronological order but the loop returns them in the order\n",
    "        # of ascending distance to the first engagement tag\n",
    "        # Therefore they have to be reversed.\n",
    "        tag_list.reverse()\n",
    "\n",
    "    # Next steps\n",
    "    if next_steps is not None:\n",
    "        previous_tag = start_tag\n",
    "        for n in range(1, next_steps + 1):\n",
    "            if previous_tag is not None:\n",
    "                next_tag = previous_tag.find_next_sibling(tag_name, **kwargs)\n",
    "                previous_tag = next_tag\n",
    "                if next_tag is not None:\n",
    "                    tag_list.append(next_tag)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the examle above we started from the final website where the content is. However, in the general case we need a protocol that produces the URLs for any given date for these websites. \n",
    "For this we use the website that has a regular URL and search for the item that carry the links to the final websites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a good example of what to me seems like the most efficient and robust way of scraping websites. After we have fetched the website, we narrow in on those bits of the content that we predict the objects of interest to be in, here `question_soup` and `pm_section`. Now we search first in the most narrow location for what we want and only if we don't find anything here, we move up. This requires supposedly reduces / eliminates the number of False Positives whilst allowing for (predictable) changes in the strucutre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_pmq_links(date,base_url = \"https://hansard.parliament.uk\"):\n",
    "    # 1) Fetch\n",
    "    def fetch(date,base_url):\n",
    "        url = base_url + \"/Commons/\" + date\n",
    "        page = requests.get(url)\n",
    "        return page\n",
    "    \n",
    "    \n",
    "    soup = brew_the_soup(fetch(date,base_url).content,'lxml')\n",
    "\n",
    "    # 2) Zoom in on the elements of the structure where the objects of interest CAN be\n",
    "    def scrape_soup(soup):\n",
    "        \n",
    "        question_soup = robust_tag_finder(\n",
    "            start_soup=soup,\n",
    "            tagname=\"a\",\n",
    "            text=re.compile(r\"Oral\\s*Answer(s)?\\s*to\\s*Question(s)?\\s*\\n*\", re.I),\n",
    "        )\n",
    "\n",
    "        if question_soup is not None:\n",
    "            pm_section_temp = robust_tag_finder(\n",
    "                start_soup=question_soup, \n",
    "                tagname=\"a\", \n",
    "                text=re.compile(r\"P?rime Minister\\n*\", re.I)\n",
    "            )\n",
    "            tag_class = \" \".join(pm_section_temp[\"class\"])\n",
    "\n",
    "            if bool(re.search(r\"has-children( open)?\",tag_class)):\n",
    "                pm_section = pm_section_temp\n",
    "            else:\n",
    "                pm_section = None\n",
    "        else:\n",
    "            pm_section = None\n",
    "\n",
    "        # 3) Search from the most narrow location upwards (pm_section first, question_soup second)\n",
    "        pmq_links = list()\n",
    "\n",
    "        if question_soup is not None:\n",
    "            if pm_section is not None:\n",
    "                for bullet in pm_section.findAll('a'):\n",
    "                    if not bool(re.search(r\"P?rime Minister\\n*\", bullet.text, re.I)):\n",
    "                        pmq_links.append(bullet.get(\"href\"))\n",
    "\n",
    "            # If no designated pm section was found, search in the whole question_soup\n",
    "            else:                    \n",
    "                engagement_tags = [tag.parent for tag in question_soup.findAll('a',text=re.compile(r'Engagements',re.I))]\n",
    "                last_engagement_tag = engagement_tags[-1]\n",
    "                following_tags = findAll_surrounding_tags(\n",
    "                    start_tag=last_engagement_tag,\n",
    "                    next_steps=3,\n",
    "                    tag_name=\"li\",\n",
    "                    class_=\"no-children\",\n",
    "                )\n",
    "                pmq_tags = engagement_tags + following_tags\n",
    "\n",
    "                for bullet in pmq_tags:\n",
    "                    pmq_links.append(bullet.a.get(\"href\"))\n",
    "\n",
    "        # 4) Convert the url-bits into links that we can scrape \n",
    "        pmq_links_final = list()\n",
    "        for link in pmq_links:\n",
    "            pmq_links_final.append(base_url + link)\n",
    "        return pmq_links_final\n",
    "    \n",
    "    pmq_links_final = scrape_soup(soup)\n",
    "    \n",
    "    return pmq_links_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1979-01-18': ['https://hansard.parliament.uk/Commons/1979-01-18/debates/d7952bdb-a5f4-4510-abfa-4806295650ee/PrimeMinister(Engagements)',\n",
       "  'https://hansard.parliament.uk/Commons/1979-01-18/debates/6cd5b624-da84-4747-abb7-699d785073c2/NationalEconomicdevelopmentCouncil'],\n",
       " '1982-07-27': ['https://hansard.parliament.uk/Commons/1982-07-27/debates/d8026e1d-5ea4-471f-8dc0-3d57056e4cc2/FactoryClosures',\n",
       "  'https://hansard.parliament.uk/Commons/1982-07-27/debates/7a87ccce-4da2-42b2-96b8-718f36f651b0/Engagements']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_link = dict()\n",
    "for d in ['1979-01-18','1982-07-27']:\n",
    "    date_to_link[d] = retrieve_pmq_links(d)\n",
    "\n",
    "date_to_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerating\n",
    "Webscraping many pages can be extremely time consuming. The bottleneck is always the process of fetchting the HTML file. \n",
    "It is highly recommandable to isolate this step from the rest of the scraping process and to store the html files locally in `pickle` files. \n",
    "In addition, parallelization (e.g. with `waf`) yields large performance boosts, when a large number of websites are fetched.\n",
    "https://hansard.parliament.uk/Commons/1982-07-27\n",
    "https://hansard.parliament.uk/Commons/1979-01-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file 'C:\\\\Users\\\\jankn\\\\AppData\\\\Local\\\\Temp\\\\tmp2nza223r'. \n",
      "Embedding SnakeViz in this document...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe id='snakeviz-337bbb8a-aead-11e9-92e6-3800251969f9' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-337bbb8a-aead-11e9-92e6-3800251969f9\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/C%3A%5CUsers%5Cjankn%5CAppData%5CLocal%5CTemp%5Ctmp2nza223r\")</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%snakeviz retrieve_pmq_links('1979-01-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_html(date,base_url=\"https://hansard.parliament.uk\"):\n",
    "    page = requests.get(base_url + \"/Commons/\" + date)\n",
    "    page_dict = {date: page.content}\n",
    "    \n",
    "    with open(\"./html_files/base_page_{}\".format(date), \"wb\") as f:\n",
    "        pickle.dump(page_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_html(\"1979-01-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(date):\n",
    "    with open(\"./html_files/base_page_{}\".format(date), \"rb\") as f:\n",
    "        content_page = pickle.load(f)[date]\n",
    "    \n",
    "    return content_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_pmq_links_pickle(date,base_url = \"https://hansard.parliament.uk\"):\n",
    "    # 1) Fetch\n",
    "    content_page = load_pickle(date)\n",
    "    soup = brew_the_soup(content_page,'lxml')\n",
    "\n",
    "    # 2) Zoom in on the elements of the structure where the objects of interest CAN be\n",
    "    def scrape_soup(soup):\n",
    "        \n",
    "        question_soup = robust_tag_finder(\n",
    "            start_soup=soup,\n",
    "            tagname=\"a\",\n",
    "            text=re.compile(r\"Oral\\s*Answer(s)?\\s*to\\s*Question(s)?\\s*\\n*\", re.I),\n",
    "        )\n",
    "\n",
    "        if question_soup is not None:\n",
    "            pm_section_temp = robust_tag_finder(\n",
    "                start_soup=question_soup, \n",
    "                tagname=\"a\", \n",
    "                text=re.compile(r\"P?rime Minister\\n*\", re.I)\n",
    "            )\n",
    "            tag_class = \" \".join(pm_section_temp[\"class\"])\n",
    "\n",
    "            if bool(re.search(r\"has-children( open)?\",tag_class)):\n",
    "                pm_section = pm_section_temp\n",
    "            else:\n",
    "                pm_section = None\n",
    "        else:\n",
    "            pm_section = None\n",
    "\n",
    "        # 3) Search from the most narrow location upwards (pm_section first, question_soup second)\n",
    "        pmq_links = list()\n",
    "\n",
    "        if question_soup is not None:\n",
    "            if pm_section is not None:\n",
    "                for bullet in pm_section.findAll('a'):\n",
    "                    if not bool(re.search(r\"P?rime Minister\\n*\", bullet.text, re.I)):\n",
    "                        pmq_links.append(bullet.get(\"href\"))\n",
    "\n",
    "            # If no designated pm section was found, search in the whole question_soup\n",
    "            else:                    \n",
    "                engagement_tags = [tag.parent for tag in question_soup.findAll('a',text=re.compile(r'Engagements',re.I))]\n",
    "                last_engagement_tag = engagement_tags[-1]\n",
    "                following_tags = findAll_surrounding_tags(\n",
    "                    start_tag=last_engagement_tag,\n",
    "                    next_steps=3,\n",
    "                    tag_name=\"li\",\n",
    "                    class_=\"no-children\",\n",
    "                )\n",
    "                pmq_tags = engagement_tags + following_tags\n",
    "\n",
    "                for bullet in pmq_tags:\n",
    "                    pmq_links.append(bullet.a.get(\"href\"))\n",
    "\n",
    "        # 4) Convert the url-bits into links that we can scrape \n",
    "        pmq_links_final = list()\n",
    "        for link in pmq_links:\n",
    "            pmq_links_final.append(base_url + link)\n",
    "        return pmq_links_final\n",
    "    \n",
    "    pmq_links_final = scrape_soup(soup)\n",
    "    \n",
    "    return pmq_links_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://hansard.parliament.uk/Commons/1979-01-18/debates/d7952bdb-a5f4-4510-abfa-4806295650ee/PrimeMinister(Engagements)',\n",
       " 'https://hansard.parliament.uk/Commons/1979-01-18/debates/6cd5b624-da84-4747-abb7-699d785073c2/NationalEconomicdevelopmentCouncil']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = retrieve_pmq_links_pickle(date=\"1979-01-18\")\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.4 ms ± 4.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit retrieve_pmq_links_pickle(date=\"1979-01-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.83 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "619 ms ± 635 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit retrieve_pmq_links(date=\"1979-01-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
