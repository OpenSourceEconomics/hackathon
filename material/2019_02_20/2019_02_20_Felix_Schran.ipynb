{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem:\n",
    "\n",
    "- Our occupational choice model is simple and static... but has many parameters to estimate\n",
    "- $K = $ Occupations $\\times$ years $\\approx$ 3000, $N = 50$mio, 20GB\n",
    "\n",
    "Using Python for data analysis:\n",
    "- Pandas is great for datasets that fit well in Memory (< 1GB?)\n",
    "- Python itself was not developed for parallelization (Global Interpreter Lock)\n",
    "- Move to Scala and Java based Big Data frameworks?... (map-reduce approaches: Apache Spark, Hadoop)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask: Scalable analytics in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from https://towardsdatascience.com/why-every-data-scientist-should-use-dask-81b2b850e15b, \n",
    "\n",
    "Dask is the most **revolutionary tool for data processing**:\n",
    "\n",
    "1. If struggling with data **larger than RAM**\n",
    "2. Dask **supports the Pandas dataframe** and **Numpy array data** structures\n",
    "3. Run on your **local computer** or scale to a **cluster**\n",
    "4. With **minimal code changes**, run code code in **parallel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basics:\n",
    "- Dask is maintained by Anaconda developers since 2015\n",
    "- It has an amazing dashboard to see what is going on\n",
    "- Main package:\n",
    "\n",
    "`conda install dask`\n",
    "- Make scikit-learn work with large datasets:\n",
    "\n",
    "`conda install -c conda-forge dask-ml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is a flexible library for parallel computing in Python with two main features:\n",
    "1. Dynamic task scheduler + task graph execution (in parallel where possible, similar to OpenMP?)\n",
    "2. “Big Data” collections like parallel arrays, dataframes, and lists that extend NumPy and Pandas to larger-than-memory or distributed environments\n",
    "\n",
    "\n",
    "What can you use it for? (I need it for point two):\n",
    "1. Make your numpy (+ numba) code parallel with minimal adjustments\n",
    "2. Work on datasets larger than memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parallelize code with dask delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dask import delayed, compute\n",
    "from time import sleep\n",
    "\n",
    "@delayed\n",
    "def increase(x):\n",
    "    sleep(0.0)\n",
    "    y = x + 1\n",
    "    return y\n",
    "\n",
    "@delayed\n",
    "def square(x):\n",
    "    sleep(0.0)\n",
    "    y = x**2\n",
    "    return y\n",
    "\n",
    "@delayed\n",
    "def summed(l):\n",
    "    sleep(0.0)\n",
    "    y = np.sum(l)\n",
    "    return y\n",
    "\n",
    "squared = []\n",
    "for x in range(5):\n",
    "    \n",
    "    x_inc = increase(x)\n",
    "    x_square = square(x_inc)\n",
    "    \n",
    "    squared.append(x_square)\n",
    "\n",
    "sum_of_squares = summed(squared)\n",
    "\n",
    "#print(squared)\n",
    "print(sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_squares.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_squares.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dask Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas reads everything into memory\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "n_obs = 1000\n",
    "ages = np.round(np.random.uniform(20, 50, n_obs), 0)\n",
    "skills = np.random.randn(n_obs)\n",
    "\n",
    "df = pd.DataFrame({'age': ages, 'skill': skills})\n",
    "\n",
    "df['wage'] = df['skill'] * 3 + df['age'] * 2 + np.random.randn(n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.from_pandas(df, npartitions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 More advanced operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('age')[['skill', 'wage']].mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Map your functions to each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(ddf):\n",
    "    return ddf**2\n",
    "    \n",
    "df['age_squared'] = df['age'].map_partitions(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Save large files efficiently\n",
    "\n",
    "Problem: the amount of tasks in the graph quickly becomes large making it slow\n",
    "\n",
    "Save steps to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet('parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Online Regression - Estimate a linear relationship in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google does not update their models by recomputing their complete model when 1 new observation arrives...\n",
    "\n",
    "https://en.wikipedia.org/wiki/Online_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.wrappers import Incremental\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "ols_sgd = Incremental(\n",
    "    SGDRegressor(\n",
    "        loss='squared_loss',\n",
    "        penalty='none',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['wage'].values\n",
    "X = df[['age', 'skill']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols_sgd.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = results.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
